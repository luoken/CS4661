{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4661 Intro To Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | CIN |\n",
    "| :---: | ---\n",
    "|Danny Padilla|304542295|\n",
    "|Ken Luo|300706047|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Suppose that we want to build a decision tree classifier to perform weather forecasting! We have 3 features (Temp, Humidity, Wind), and a binary Label (sunny/rainy). The following table includes the data collected over the past two weeks.\n",
    "#### Based on this data, which feature is the best feature to put on the top of the tree? Justify your answer by providing detailed Entropy calculations.\n",
    "\n",
    "| Temp | Humidity | Windy | Label |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| high | low | yes | sunny |\n",
    "| low | high | yes | rainy |\n",
    "| high | low | no | sunny |\n",
    "| high | high | no | sunny |\n",
    "| mild | mild | no| sunny |\n",
    "| mild | high | no | rainy |\n",
    "| low | mild | yes | rainy |\n",
    "| low | low | yes | rainy |\n",
    "| low | high | yes | rainy |\n",
    "| high | low | no | sunny |\n",
    "| high | mild | no | sunny |\n",
    "| mild | mild | no | sunny |\n",
    "| mild | high | no | rainy |\n",
    "| low | mild | yes | rainy |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunny/Rainy\n",
      " Entropy Before Split:  1.0 \n",
      "\n",
      "Wind\n",
      " Entropy Before Split: 1.0\n",
      " * Windy     -  0.65\n",
      " * NOT Windy -  0.81\n",
      " Entropy After Split: 0.74\n",
      " Information Gain: 1.0 - 0.74 = 0.26 \n",
      "\n",
      "Humidity\n",
      " Entropy Before Split: 1.0\n",
      " * Low  -  0.81\n",
      " * Mild -  0.97\n",
      " * High -  0.72\n",
      " Entropy After Split: 0.83\n",
      " Information Gain: 1.0 - 0.83 = 0.17 \n",
      "\n",
      "Temp\n",
      " Entropy Before Split: 1.0\n",
      " * Low  -  0.0\n",
      " * Mild -  1.0\n",
      " * High -  0.0\n",
      " Entropy After Split: 0.29                   <----------\n",
      " Information Gain: 1.0 - 0.29 = 0.71         <----------\n",
      "\n",
      "######## The best feature is TEMP since it will minimize the entropy. ########\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "total_sunny = {True: 7, False: 7} # total_rainy = same                                                                                        \n",
    "total_windy = {\"yes\": 6, \"no\": 8}\n",
    "total_humidity = {\"low\": 4, \"mild\": 5, \"high\": 5}\n",
    "total_temp = {\"low\": 5, \"mild\": 4, \"high\": 5}\n",
    "'''\n",
    "import math\n",
    "\n",
    "def entropy(measure): # define entropy function H(X)\n",
    "    sum = 0\n",
    "    for v in measure:\n",
    "        if(v == 0): # domain check\n",
    "            pass\n",
    "        else:\n",
    "            sum -= round( (v) * math.log2(v), 2 )\n",
    "    return sum\n",
    "\n",
    "def split_avg(bit, v):\n",
    "    sum = 0\n",
    "    for x, y in bit, v:\n",
    "        sum += round(x * y, 2)\n",
    "    return sum\n",
    "\n",
    "''' ###############################################################\n",
    "sunny_rainy = {\n",
    "    True: 7,\n",
    "    False: 7 }\n",
    "'''\n",
    "sunny_count = entropy([7/14, 7/14])\n",
    "print(\"Sunny/Rainy\")\n",
    "print(\" Entropy Before Split: \", sunny_count, \"\\n\")\n",
    "\n",
    "\n",
    "''' ###############################################################\n",
    "windy = {\n",
    "    True: {\"Sunny\": 1, \"Rainy\": 5},\n",
    "    False: {\"Sunny\": 6, \"Rainy\": 2} }\n",
    "'''\n",
    "windy_count = entropy([1/6, 5/6])\n",
    "not_windy_count = entropy([6/8, 2/8])\n",
    "wind_avg = [6/14, 8/14]\n",
    "windy_split_avg = round( (windy_count * 6/14) + (not_windy_count * 8/14), 2)\n",
    "windy_ig = sunny_count - windy_split_avg\n",
    "print(\"Wind\")\n",
    "print(\" Entropy Before Split:\", sunny_count)\n",
    "print(\" * Windy     - \", windy_count)\n",
    "print(\" * NOT Windy - \", not_windy_count)\n",
    "print(\" Entropy After Split:\", windy_split_avg )\n",
    "print(\" Information Gain:\", sunny_count, \"-\", windy_split_avg, \"=\", windy_ig, \"\\n\")\n",
    "\n",
    "\n",
    "''' ###############################################################\n",
    "humidity = {\n",
    "    \"low\": {\"Sunny\": 3, \"Rainy\": 1}, # \n",
    "    \"mild\": {\"Sunny\": 3, \"Rainy\": 2},\n",
    "    \"high\": {\"Sunny\": 1, \"Rainy\": 4} }\n",
    "'''\n",
    "humidity_low_count = entropy([3/4, 1/4])\n",
    "humidity_mild_count = entropy([3/5, 2/5])\n",
    "humidity_high_count = entropy([1/5, 4/5])\n",
    "humidity_avg = [4/14, 5/14, 5/14]\n",
    "humidity_split_avg = round( (humidity_low_count * 4/14) +  (humidity_mild_count * 5/14) + (humidity_high_count * 5/14), 2)\n",
    "humidity_ig = round(sunny_count - humidity_split_avg, 2)\n",
    "print(\"Humidity\")\n",
    "print(\" Entropy Before Split:\", sunny_count)\n",
    "print(\" * Low  - \", humidity_low_count)\n",
    "print(\" * Mild - \", humidity_mild_count)\n",
    "print(\" * High - \", humidity_high_count)\n",
    "print(\" Entropy After Split:\", humidity_split_avg)\n",
    "print(\" Information Gain:\", sunny_count, \"-\", humidity_split_avg,\"=\", humidity_ig,\"\\n\")\n",
    "\n",
    "\n",
    "''' ###############################################################\n",
    "temp = {\n",
    "    \"low\": {\"Sunny\": 0, \"Rainy\": 5},\n",
    "    \"mild\": {\"Sunny\": 2, \"Rainy\": 2},\n",
    "    \"high\": {\"Sunny\": 5, \"Rainy\": 0} }\n",
    "'''\n",
    "temp_low_count = entropy([0/5, 5/5])\n",
    "temp_mild_count = entropy([2/4, 2/4])\n",
    "temp_high_count = entropy([5/5, 0/5])\n",
    "temp_avg = [5/14, 4/14, 5/14]\n",
    "temp_split_avg = round( (temp_low_count * 5/14) +  (temp_mild_count * 4/14) + (temp_high_count * 5/14), 2)\n",
    "temp_ig = sunny_count - temp_split_avg\n",
    "print(\"Temp\")\n",
    "print(\" Entropy Before Split:\", sunny_count)\n",
    "print(\" * Low  - \", temp_low_count)\n",
    "print(\" * Mild - \", temp_mild_count)\n",
    "print(\" * High - \", temp_high_count)\n",
    "print(\" Entropy After Split:\", temp_split_avg,\"                  <----------\")\n",
    "print(\" Information Gain:\", sunny_count, \"-\", temp_split_avg,\"=\", temp_ig,\"        <----------\\n\")\n",
    "\n",
    "print(\"######## The best feature is TEMP since it will minimize the entropy. ########\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Read the\tiris\tdataset\tfrom\tthe\tfollowing\tURL: 'https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv' and\tassign\tit\tto a\tPandas\tDataFrame\tas\tyou\tlearned in\ttutorial\tLab2-3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports panda as pd and read in the csv file storing it to the df variable. Prints out df to make sure values are inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "5             5.4          3.9           1.7          0.4     setosa\n",
       "6             4.6          3.4           1.4          0.3     setosa\n",
       "7             5.0          3.4           1.5          0.2     setosa\n",
       "8             4.4          2.9           1.4          0.2     setosa\n",
       "9             4.9          3.1           1.5          0.1     setosa\n",
       "10            5.4          3.7           1.5          0.2     setosa\n",
       "11            4.8          3.4           1.6          0.2     setosa\n",
       "12            4.8          3.0           1.4          0.1     setosa\n",
       "13            4.3          3.0           1.1          0.1     setosa\n",
       "14            5.8          4.0           1.2          0.2     setosa\n",
       "15            5.7          4.4           1.5          0.4     setosa\n",
       "16            5.4          3.9           1.3          0.4     setosa\n",
       "17            5.1          3.5           1.4          0.3     setosa\n",
       "18            5.7          3.8           1.7          0.3     setosa\n",
       "19            5.1          3.8           1.5          0.3     setosa\n",
       "20            5.4          3.4           1.7          0.2     setosa\n",
       "21            5.1          3.7           1.5          0.4     setosa\n",
       "22            4.6          3.6           1.0          0.2     setosa\n",
       "23            5.1          3.3           1.7          0.5     setosa\n",
       "24            4.8          3.4           1.9          0.2     setosa\n",
       "25            5.0          3.0           1.6          0.2     setosa\n",
       "26            5.0          3.4           1.6          0.4     setosa\n",
       "27            5.2          3.5           1.5          0.2     setosa\n",
       "28            5.2          3.4           1.4          0.2     setosa\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "\n",
    "#read in csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Split the\t dataset\t into\t testing\t and\t training sets\t with\t the\t following\t parameters: test_size=0.4,\trandom_state=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports train_test_split, set data to the data frame labels \"sepal length, sepal width, petal length, petal width\" then sets label to the data frame \"species\". split up training data and testing data along with their labels to a .6 training set, the test_size would be .4 and the random state 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "label = df['species']\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size = 0.4, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Instantiate\ta KNN object with K=3, train it on the training set and test it on the testing set. Then, calculate\tthe\taccuracy of your prediction as \tyou learned\tin Lab3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports kneighborsClassifier along with accuracy_score. Set the number of neighbors to 3. knn.fit will train the data. data_predict will be testing data. The score will be an accuracy score with the testing data and the label tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "K = 3\n",
    "knn = KNeighborsClassifier(n_neighbors = K)\n",
    "\n",
    "knn.fit(data_train, label_train)\n",
    "\n",
    "data_predict = knn.predict(data_test)\n",
    "\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Repeat\tpart (c) for K=1, K=5, K=7,\tK=15, K=28,\tK=60 (you can simply write a “for loop”\ton a list with\tthese value to repeat the process for you, and save\tthe\tfinal accuracy results in a\tlist (array)!).\tDoes the accuracy always get better\tby increasing K?\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the same as above but changes k to 1, 5, 7, 15, 28, and 60. Loop the neighbor value so it'll iterate through the array. Append each score to another array and print the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666666666666667, 0.98333333333333328, 0.98333333333333328, 0.98333333333333328, 0.94999999999999996, 0.80000000000000004]\n"
     ]
    }
   ],
   "source": [
    "K = [1,5,7,15,28,60]\n",
    "scores = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(data_train, label_train)\n",
    "    data_predict = knn.predict(data_test)\n",
    "    score = accuracy_score(data_predict, label_test)\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "#too many neighbots will cause the accuracy to go down, but it seems like 5,7,15 will yield the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Now,\tsuppose\tthat\twe\twould\tlike\tto\tmake\tprediction\tbased\ton\tonly\tONE\tsingle\tfeature. To\tfind\tthe\tbest\tsingle\tfeature,\twe\thave\tto\ttry\tevery\tfeature\tindividually.\tIn\tother\tword, we\t have\t to\t repeat\t part (c)\t 4\t times\t (each\t time\t using\t only\t one\t of\t the\t 4\t features),\t and compute\t the\taccuracy\teach\t time.\tThen,\tcheck\t the\taccuracies.\tWhich\tindividual\t feature provide\t the\t best\t accuracy\t (the\t best\t feature)?\t Which\t one\t is\t the\t second\tbest\tfeature? (Note:\tyou\thave\tto\ttrain,\ttest,\tand\tevaluate your\tmodel\t4\ttimes,\teach\ttime\ton\ta\tdataset including\tonly\tone\tof\tthe\tfeatures.\tYou\tmay\twant\tto\twrite\ta\t“for\tloop”\tto\tgenerate\tthe\tdatasets,\t train,\t test,\tand\tcompute\t the\taccuracy\teach\t time,\tand\tsave\t the\t final\taccuracy results\tin\ta\tlist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set k back to 3 because we changed it a couple times in the previous exercise. Instead of using all the features, we had to select only one value so we used values.reshape to only select one data inside data_train at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6333333333333333, 0.53333333333333333, 0.96666666666666667, 0.93333333333333335]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "singleFeat = []\n",
    "\n",
    "for data in data_train:\n",
    "    knn = KNeighborsClassifier(n_neighbors = K)\n",
    "    knn.fit(data_train[data].values.reshape(-1,1), label_train)\n",
    "    data_predict = knn.predict(data_test[data].values.reshape(-1,1))\n",
    "    score = accuracy_score(data_predict, label_test)\n",
    "    singleFeat.append(score)\n",
    "\n",
    "print(singleFeat)\n",
    "\n",
    "# it seems petal_length is the best feature. The second best feature is the petal_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Now,\twe\twant\tto\trepeat\tpart\t(e),\tthis\ttime\tusing\ttwo\tfeatures.\tyou\thave\tto\ttrain,\ttest,\tand\tevaluate\t your\t model\t for\t 6\t different\t cases:\t using\t (1st and\t 2nd features),\t (1st and\t 3rd features),\t(1st and\t4th\t\tfeatures),\t(2nd\t\tand\t3rd\t\tfeatures), (2nd and\t4th features), (3rd and\t4th\t\tfeatures)! \n",
    "\n",
    "#### Which “feature\tpair” provide\tthe\tbest\taccuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features will be an empty array, it'll populate as it iterates through data_train. We select two features at a time and append the scores generated to doublefeatscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65000000000000002, 0.93333333333333335, 0.98333333333333328, 0.94999999999999996, 0.96666666666666667, 0.96666666666666667]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "doubleFeatScores = []\n",
    "for d in data_train:\n",
    "    features.append(d)\n",
    "    \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = K)\n",
    "knn.fit(data_train[[features[0], features[1]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[0], features[1]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "knn.fit(data_train[[features[0], features[2]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[0], features[2]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "knn.fit(data_train[[features[0], features[3]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[0], features[3]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "knn.fit(data_train[[features[1], features[2]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[1], features[2]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "knn.fit(data_train[[features[1], features[3]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[1], features[3]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "knn.fit(data_train[[features[2], features[3]]], label_train)\n",
    "data_predict = knn.predict(data_test[[features[2], features[3]]])\n",
    "score = accuracy_score(data_predict, label_test)\n",
    "doubleFeatScores.append(score)\n",
    "\n",
    "print(doubleFeatScores)\n",
    "\n",
    "# the one that provides the best accuracy would be 1st and 4th feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. BigQuestion: Does the\t“best\tfeature\tpair” from\tpart\t(f) contain of both “first best\tfeature” and\t“second\tbest\tfeature” from\tpart\t(e)?\t In\tother\tword,\tcan\twe\tconclude\tthat\tthe\t“best two\tfeatures”\tfor\tclassification\tare\tthe\t“first\tbest\tindividual\tfeature”\tand\tthe\t“second\tbest individual\tfeature”\ttogether?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No it does not contain both the first best feature and the second best feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h. Optional\tQuestion:\tJustify\tyour\tanswer\tto\tpart\t(g)!\t\tIf\tyes,\twhy?\t\tIf\tno,\twhy\tnot? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first best feature and the second best feature does not necessarily mean that it will yield the best results. Given by the results of the single feature, the best one would be the petal length, but when you take two features, the one that yields the best result would be sepal_length along with petal_width."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
